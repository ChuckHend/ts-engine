{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "pd.options.display.max_rows = 99999\n",
    "pd.options.display.max_columns = 99999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup engine to archbox psql database\n",
    "arch_engine = create_engine(\"postgresql://<user>:<pass>192.168.0.2:5432/sampalytics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of tickers in our db\n",
    "tickers = arch_engine.engine.execute('SELECT DISTINCT ticker from stocks.minute').fetchall()\n",
    "# convert to list, ie get the tickers out of the tuples\n",
    "tickers = [x[0] for x in tickers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'AMD'\n",
    "n_predictors = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_list(outcome, ticks, n_predictors):\n",
    "    # remove the outcome var so we dont randomly select it and create duplicates\n",
    "    ticks = [x for x in ticks if x not in outcome] # .remove causes pointer issue\n",
    "    # convert list of tickers to df so we can index\n",
    "    df = pd.DataFrame(ticks)\n",
    "    # randomly select the rows we want to take\n",
    "    rows = random.sample(range(len(ticks)), n_predictors)\n",
    "    # then select the rows subset\n",
    "    df = df.iloc[rows]\n",
    "    return [outcome] + list(df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = prune_list(outcome=outcome, ticks=tickers, n_predictors=n_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: AMD: 1\n",
      "Loading: ANAT: 2\n",
      "Loading: NTRA: 3\n",
      "Loading: KMI: 4\n",
      "Loading: IROQ: 5\n",
      "Loading: CCD: 6\n",
      "Loading: FAD: 7\n",
      "Loading: IXY: 8\n",
      "Loading: FBIZ: 9\n",
      "Loading: INDY: 10\n",
      "Loading: CCLP: 11\n",
      "Loading: CPLP: 12\n",
      "Loading: ROBT: 13\n",
      "Loading: CNSL: 14\n",
      "Loading: MNST: 15\n",
      "Loading: FINX: 16\n",
      "Loading: DNLI: 17\n",
      "Loading: CARS: 18\n",
      "Loading: KTOV: 19\n",
      "Loading: MARA: 20\n",
      "Loading: GSBC: 21\n",
      "Loading: RFEM: 22\n",
      "Loading: CODA: 23\n",
      "Loading: ARRS: 24\n",
      "Loading: SPA: 25\n",
      "Loading: TC: 26\n",
      "Loading: ETX: 27\n",
      "Loading: PVTL: 28\n",
      "Loading: DOVA: 29\n",
      "Loading: OCSL: 30\n",
      "Loading: AGS: 31\n",
      "Loading: CYAD: 32\n",
      "Loading: AMRB: 33\n",
      "Loading: FORR: 34\n",
      "Loading: PFIN: 35\n",
      "Loading: HMI: 36\n",
      "Loading: TUSA: 37\n",
      "Loading: RBBN: 38\n",
      "Loading: CERC: 39\n",
      "Loading: FEMB: 40\n",
      "Loading: CCCR: 41\n",
      "Loading: CUTR: 42\n",
      "Loading: CENT: 43\n",
      "Loading: KERX: 44\n",
      "Loading: IIJI: 45\n",
      "Loading: HTHT: 46\n",
      "Loading: JCS: 47\n",
      "Loading: ILMN: 48\n",
      "Loading: IFEU: 49\n",
      "Loading: BIIB: 50\n",
      "Loading: DTYS: 51\n",
      "Loading: CREE: 52\n",
      "Loading: CARA: 53\n",
      "Loading: SCON: 54\n",
      "Loading: LMRKN: 55\n",
      "Loading: ENTG: 56\n",
      "Loading: CHKP: 57\n",
      "Loading: QRHC: 58\n",
      "Loading: WIRE: 59\n",
      "Loading: ITCI: 60\n",
      "Loading: FULT: 61\n",
      "Loading: JNCE: 62\n",
      "Loading: FPA: 63\n",
      "Loading: IAC: 64\n",
      "Loading: CRBP: 65\n",
      "Loading: NANO: 66\n",
      "Loading: NAVI: 67\n",
      "Loading: LKM: 68\n",
      "Loading: GLAD: 69\n",
      "Loading: IRDM: 70\n",
      "Loading: HYGS: 71\n",
      "Loading: CTIC: 72\n",
      "Loading: FIN: 73\n",
      "Loading: NEON: 74\n",
      "Loading: FNGN: 75\n",
      "Loading: FEX: 76\n",
      "Loading: MZOR: 77\n",
      "Loading: FTGC: 78\n",
      "Loading: FISV: 79\n",
      "Loading: KIN: 80\n",
      "Loading: PXLW: 81\n",
      "Loading: ADTN: 82\n",
      "Loading: LHCG: 83\n",
      "Loading: AVXS: 84\n",
      "Loading: ANSS: 85\n",
      "Loading: FMK: 86\n",
      "Loading: CASM: 87\n",
      "Loading: ATLC: 88\n",
      "Loading: HMNF: 89\n",
      "Loading: UHAL: 90\n",
      "Loading: GTIM: 91\n",
      "Loading: ANTH: 92\n",
      "Loading: CVV: 93\n",
      "Loading: ISNS: 94\n",
      "Loading: ZUO: 95\n",
      "Loading: IRWD: 96\n",
      "Loading: KANG: 97\n",
      "Loading: FCVT: 98\n",
      "Loading: ALTR: 99\n",
      "Loading: KLXI: 100\n",
      "Loading: CHSCN: 101\n"
     ]
    }
   ],
   "source": [
    "# custom header\n",
    "full_df = pd.DataFrame(columns=['dtg'])\n",
    "# predictors = ['open', 'high', 'low', 'close', 'volume']\n",
    "predictors = ['close', 'volume'] # try less to save memory\n",
    "i = 1\n",
    "for ticker in tickers:\n",
    "    header = ['dtg'] + [x + '_' + str(ticker) for x in predictors]\n",
    "    select=', '.join(['dtg'] + predictors)\n",
    "    # d = arch_engine.engine.execute(\"SELECT DISTINCT dtg, open, high, low, close, volume from stocks.minute WHERE ticker='{}'\".format(ticker)).fetchall()\n",
    "    d = arch_engine.engine.execute(\"SELECT DISTINCT {} from stocks.minute WHERE ticker='{}'\".format(select, ticker)).fetchall()\n",
    "    d = pd.DataFrame(d, columns=header).dropna()\n",
    "    print('Loading: {}: {}'.format(ticker, i))\n",
    "    i = i + 1\n",
    "    full_df = pd.merge(full_df, d, on='dtg', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ie. row 1 is Jan 1, row 2 in Jan 2.\n",
    "full_df.sort_values('dtg', inplace=True)\n",
    "# and do a forward fill\n",
    "full_df.fillna(method='ffill', inplace=True)\n",
    "# then drop the NA\n",
    "full_df.dropna(inplace=True)\n",
    "# rename dtg to date for TS package\n",
    "full_df.rename(columns={'dtg':'Date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv('/mnt/ubudata/projects/data/AMD_plus_100.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue in main-notebook of forecast engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
